{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "5i7PPGdc2aEO",
        "outputId": "e2132bc6-d974-4fb0-a109-d93f8addc81e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-14bbcacd9e73>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;31m# Execute if running as script\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m     \u001b[0mrun_full_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-2-14bbcacd9e73>\u001b[0m in \u001b[0;36mrun_full_pipeline\u001b[0;34m()\u001b[0m\n\u001b[1;32m    592\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun_full_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m     \u001b[0;31m# 1) Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m     model, best_acc = train_model(\n\u001b[0m\u001b[1;32m    595\u001b[0m         \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m         \u001b[0;31m# Increased from 250 to 300\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-14bbcacd9e73>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(num_epochs, batch_size, width_multiplier, dropout, se_reduction, use_mixup, mixup_alpha)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# 1) Load Data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_cifar10_dataloaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;31m# 2) Create Model with SE blocks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-14bbcacd9e73>\u001b[0m in \u001b[0;36mget_cifar10_dataloaders\u001b[0;34m(batch_size, num_workers)\u001b[0m\n\u001b[1;32m     79\u001b[0m     ])\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     train_dataset = torchvision.datasets.CIFAR10(\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_integrity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dataset not found or corrupted. You can use download=True to download it\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m_check_integrity\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_list\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0mfpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_integrity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mcheck_integrity\u001b[0;34m(fpath, md5)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmd5\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcheck_md5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mcheck_md5\u001b[0;34m(fpath, md5, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcheck_md5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmd5\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcalculate_md5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mcalculate_md5\u001b[0;34m(fpath, chunk_size)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;34m:=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mmd5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhexdigest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "#############################################################################\n",
        "# 1. Data Preparation: CIFAR-10\n",
        "#    - Includes Cutout in the training transform\n",
        "#############################################################################\n",
        "class Cutout:\n",
        "    \"\"\"\n",
        "    Randomly masks out one or more square regions of an image.\n",
        "    This version assumes the input is a tensor, not a PIL Image.\n",
        "    \"\"\"\n",
        "    def __init__(self, n_holes=1, length=16):\n",
        "        self.n_holes = n_holes\n",
        "        self.length = length\n",
        "\n",
        "    def __call__(self, img):\n",
        "        \"\"\"\n",
        "        img: tensor image of size (C, H, W)\n",
        "        \"\"\"\n",
        "        h = img.size(1)\n",
        "        w = img.size(2)\n",
        "\n",
        "        # Create a mask full of 1s\n",
        "        mask = np.ones((h, w), np.float32)\n",
        "\n",
        "        for _ in range(self.n_holes):\n",
        "            y = np.random.randint(h)\n",
        "            x = np.random.randint(w)\n",
        "\n",
        "            y1 = np.clip(y - self.length // 2, 0, h)\n",
        "            y2 = np.clip(y + self.length // 2, 0, h)\n",
        "            x1 = np.clip(x - self.length // 2, 0, w)\n",
        "            x2 = np.clip(x + self.length // 2, 0, w)\n",
        "\n",
        "            mask[y1: y2, x1: x2] = 0.\n",
        "\n",
        "        mask = torch.from_numpy(mask).to(img.device)\n",
        "        mask = mask.expand_as(img)\n",
        "        img = img * mask\n",
        "\n",
        "        return img\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + f'(n_holes={self.n_holes}, length={self.length})'\n",
        "\n",
        "\n",
        "def get_cifar10_dataloaders(batch_size=128, num_workers=2):\n",
        "    \"\"\"\n",
        "    Returns train and test DataLoaders for CIFAR-10 with standard\n",
        "    data augmentation + Cutout on the training set.\n",
        "    \"\"\"\n",
        "    # Use the standard CIFAR-10 mean and std values\n",
        "    mean = (0.4914, 0.4822, 0.4465)\n",
        "    std = (0.2470, 0.2435, 0.2616)\n",
        "\n",
        "    # Train transforms: random crop, flip, cutout, then normalize\n",
        "    transform_train = transforms.Compose([\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.AutoAugment(transforms.AutoAugmentPolicy.CIFAR10),\n",
        "        transforms.ToTensor(),\n",
        "        Cutout(n_holes=1, length=16),\n",
        "        transforms.Normalize(mean, std),\n",
        "    ])\n",
        "\n",
        "    # Test transforms: only ToTensor + normalize\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std),\n",
        "    ])\n",
        "\n",
        "    train_dataset = torchvision.datasets.CIFAR10(\n",
        "        root='./data', train=True, download=True, transform=transform_train\n",
        "    )\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset, batch_size=batch_size, shuffle=True,\n",
        "        num_workers=num_workers\n",
        "    )\n",
        "\n",
        "    test_dataset = torchvision.datasets.CIFAR10(\n",
        "        root='./data', train=False, download=True, transform=transform_test\n",
        "    )\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        test_dataset, batch_size=batch_size, shuffle=False,\n",
        "        num_workers=num_workers\n",
        "    )\n",
        "\n",
        "    return train_loader, test_loader\n",
        "\n",
        "#############################################################################\n",
        "# 2. MixUp Data Augmentation\n",
        "#############################################################################\n",
        "def mixup_data(x, y, alpha=1.0):\n",
        "    \"\"\"Returns mixed inputs and targets\"\"\"\n",
        "    if alpha > 0:\n",
        "        lam = np.random.beta(alpha, alpha)\n",
        "    else:\n",
        "        lam = 1\n",
        "\n",
        "    batch_size = x.size()[0]\n",
        "    index = torch.randperm(batch_size).to(x.device)\n",
        "\n",
        "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
        "    y_a, y_b = y, y[index]\n",
        "    return mixed_x, y_a, y_b, lam\n",
        "\n",
        "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
        "    \"\"\"Returns mixup loss\"\"\"\n",
        "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
        "\n",
        "#############################################################################\n",
        "# 3. Squeeze-and-Excitation Block\n",
        "#############################################################################\n",
        "class SEBlock(nn.Module):\n",
        "    \"\"\"Squeeze-and-Excitation block for channel attention\"\"\"\n",
        "    def __init__(self, channel, reduction=16):\n",
        "        super(SEBlock, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(channel, channel // reduction, bias=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(channel // reduction, channel, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, _, _ = x.size()\n",
        "        y = self.avg_pool(x).view(b, c)\n",
        "        y = self.fc(y).view(b, c, 1, 1)\n",
        "        return x * y.expand_as(x)\n",
        "\n",
        "#############################################################################\n",
        "# 4. Narrow ResNet-18 Implementation with SE Blocks\n",
        "#############################################################################\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"\"\"3x3 convolution with padding, no bias (used with BatchNorm).\"\"\"\n",
        "    return nn.Conv2d(\n",
        "        in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "        padding=1, bias=False\n",
        "    )\n",
        "\n",
        "class BasicBlockWithSE(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1, downsample=None, bn_momentum=0.9, se_reduction=16):\n",
        "        super(BasicBlockWithSE, self).__init__()\n",
        "        self.conv1 = conv3x3(in_planes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes, momentum=bn_momentum)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes, momentum=bn_momentum)\n",
        "        self.downsample = downsample\n",
        "        self.se = SEBlock(planes, reduction=se_reduction)\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        # Apply SE block\n",
        "        out = self.se(out)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class NarrowResNet18(nn.Module):\n",
        "    def __init__(self, num_classes=10, width_multiplier=0.6,\n",
        "                 bn_momentum=0.9, dropout=0.3, se_reduction=16):\n",
        "        \"\"\"\n",
        "        ResNet-18 with fewer channels (width_multiplier), SE blocks, and dropout.\n",
        "        \"\"\"\n",
        "        super(NarrowResNet18, self).__init__()\n",
        "        self.block_layers = [2, 2, 2, 2]\n",
        "        base_channels = [64, 128, 256, 512]\n",
        "        self.channels = [int(c * width_multiplier) for c in base_channels]\n",
        "        self.in_planes = self.channels[0]\n",
        "\n",
        "        # Initial convolution\n",
        "        self.conv1 = nn.Conv2d(3, self.in_planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(self.in_planes, momentum=bn_momentum)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        # Stages\n",
        "        self.layer1 = self._make_layer(self.channels[0], self.block_layers[0], stride=1,\n",
        "                                       bn_momentum=bn_momentum, se_reduction=se_reduction)\n",
        "        self.layer2 = self._make_layer(self.channels[1], self.block_layers[1], stride=2,\n",
        "                                       bn_momentum=bn_momentum, se_reduction=se_reduction)\n",
        "        self.layer3 = self._make_layer(self.channels[2], self.block_layers[2], stride=2,\n",
        "                                       bn_momentum=bn_momentum, se_reduction=se_reduction)\n",
        "        self.layer4 = self._make_layer(self.channels[3], self.block_layers[3], stride=2,\n",
        "                                       bn_momentum=bn_momentum, se_reduction=se_reduction)\n",
        "\n",
        "        # Global average pooling + dropout + linear\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.fc = nn.Linear(self.channels[3] * BasicBlockWithSE.expansion, num_classes)\n",
        "\n",
        "        self._init_weights()\n",
        "\n",
        "    def _make_layer(self, planes, blocks, stride=1, bn_momentum=0.9, se_reduction=16):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.in_planes != planes:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.in_planes, planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes, momentum=bn_momentum),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(BasicBlockWithSE(self.in_planes, planes, stride, downsample,\n",
        "                                     bn_momentum=bn_momentum, se_reduction=se_reduction))\n",
        "        self.in_planes = planes\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(BasicBlockWithSE(self.in_planes, planes, bn_momentum=bn_momentum,\n",
        "                                         se_reduction=se_reduction))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "        x = self.dropout(x)  # Dropout before final FC\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "#############################################################################\n",
        "# 5. Training and Evaluation Routines\n",
        "#############################################################################\n",
        "def train_one_epoch(model, device, train_loader, criterion, optimizer, use_mixup=True, mixup_alpha=1.0):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, targets in train_loader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if use_mixup:\n",
        "            # Apply mixup\n",
        "            inputs, targets_a, targets_b, lam = mixup_data(inputs, targets, alpha=mixup_alpha)\n",
        "            outputs = model(inputs)\n",
        "            loss = mixup_criterion(criterion, outputs, targets_a, targets_b, lam)\n",
        "        else:\n",
        "            # Standard forward pass\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        if not use_mixup:\n",
        "            _, predicted = outputs.max(1)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "            total += targets.size(0)\n",
        "        else:\n",
        "            # For mixup, we don't track accuracy during training\n",
        "            total += inputs.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / total\n",
        "    epoch_acc = 100.0 * correct / total if not use_mixup else 0.0\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "\n",
        "def evaluate(model, device, test_loader, criterion):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in test_loader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = outputs.max(1)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "            total += targets.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / total\n",
        "    epoch_acc = 100.0 * correct / total\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "#############################################################################\n",
        "# 6. Test Time Augmentation\n",
        "#############################################################################\n",
        "def test_time_augmentation(model, inputs, num_augmentations=10, device='cuda'):\n",
        "    \"\"\"Apply multiple augmentations to each input and average predictions\"\"\"\n",
        "    model.eval()\n",
        "    batch_size = inputs.size(0)\n",
        "    predictions = []\n",
        "\n",
        "    # Base prediction (no augmentation)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(inputs)\n",
        "        predictions.append(F.softmax(outputs, dim=1))\n",
        "\n",
        "    # Horizontal flip\n",
        "    with torch.no_grad():\n",
        "        flipped = torch.flip(inputs, dims=[3])  # Flip horizontally\n",
        "        outputs = model(flipped)\n",
        "        predictions.append(F.softmax(outputs, dim=1))\n",
        "\n",
        "    # Random shifts (small translations)\n",
        "    for _ in range(num_augmentations - 2):  # -2 because we already did base and flip\n",
        "        shifted = inputs.clone()\n",
        "\n",
        "        # Apply small random shifts (we're limited by what we can do with tensor operations)\n",
        "        pad_size = 4\n",
        "        padded = F.pad(shifted, (pad_size, pad_size, pad_size, pad_size), mode='reflect')\n",
        "\n",
        "        # For each image in the batch\n",
        "        for i in range(batch_size):\n",
        "            h_shift, w_shift = np.random.randint(0, 2*pad_size+1, size=2)\n",
        "            shifted[i] = padded[i, :, h_shift:h_shift+32, w_shift:w_shift+32]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(shifted)\n",
        "            predictions.append(F.softmax(outputs, dim=1))\n",
        "\n",
        "    # Average predictions\n",
        "    avg_preds = torch.stack(predictions).mean(dim=0)\n",
        "    return avg_preds\n",
        "\n",
        "#############################################################################\n",
        "# 7. Improved Test Data Loading\n",
        "#############################################################################\n",
        "def locate_test_file():\n",
        "    \"\"\"Try to locate the test file in various locations\"\"\"\n",
        "    potential_paths = [\n",
        "        \"cifar_test_nolabel.pkl\",\n",
        "        \"/content/cifar_test_nolabel.pkl\",\n",
        "        \"/content/drive/MyDrive/cifar_test_nolabel.pkl\",\n",
        "        \"sample_data/cifar_test_nolabel.pkl\"\n",
        "    ]\n",
        "\n",
        "    for path in potential_paths:\n",
        "        if os.path.exists(path):\n",
        "            print(f\"Found test file at: {path}\")\n",
        "            return path\n",
        "\n",
        "    # If we reach here, we couldn't find the file\n",
        "    print(\"Could not locate test file. Please check the file exists and provide the correct path.\")\n",
        "    return None\n",
        "\n",
        "def load_custom_test_set(filepath):\n",
        "    \"\"\"\n",
        "    Load and preprocess the test data from pickle file.\n",
        "    Diagnoses the structure of the file and handles different formats.\n",
        "    \"\"\"\n",
        "    print(f\"Loading data from: {filepath}\")\n",
        "\n",
        "    # Open the pickle file and load the data\n",
        "    with open(filepath, 'rb') as f:\n",
        "        data = pickle.load(f, encoding='bytes')\n",
        "\n",
        "    # Print keys to understand the structure\n",
        "    print(\"Keys in data:\", [k.decode() if isinstance(k, bytes) else k for k in data.keys()])\n",
        "\n",
        "    # Extract image data - adjust according to the actual structure\n",
        "    images = data[b'data']\n",
        "    print(\"Raw data shape:\", images.shape)\n",
        "\n",
        "    # Handle different data formats\n",
        "    if len(images.shape) == 2:  # Flattened format (N, 3072)\n",
        "        num_samples = images.shape[0]\n",
        "        # Check if this is CIFAR format (3072 = 3*32*32)\n",
        "        if images.shape[1] == 3072:\n",
        "            # Reshape from (N, 3072) to (N, 3, 32, 32)\n",
        "            images = images.reshape(num_samples, 3, 32, 32)\n",
        "            print(\"Reshaped flattened data to NCHW format:\", images.shape)\n",
        "        else:\n",
        "            raise ValueError(f\"Unexpected data shape: {images.shape}\")\n",
        "    elif len(images.shape) == 4:  # Image format (N, H, W, C)\n",
        "        # Convert from NHWC to NCHW format\n",
        "        images = np.transpose(images, (0, 3, 1, 2))\n",
        "        print(\"Converted from NHWC to NCHW format:\", images.shape)\n",
        "\n",
        "    # Convert data to float32 and normalize to [0,1]\n",
        "    images = images.astype(np.float32) / 255.0\n",
        "\n",
        "    # Convert to PyTorch tensor\n",
        "    images = torch.tensor(images, dtype=torch.float32)\n",
        "\n",
        "    return images\n",
        "\n",
        "def preprocess_test_images(images):\n",
        "    \"\"\"\n",
        "    Normalize test images using the same statistics as training.\n",
        "    \"\"\"\n",
        "    # IMPORTANT: Use the same normalization values as in training\n",
        "    mean = (0.4914, 0.4822, 0.4465)\n",
        "    std = (0.2470, 0.2435, 0.2616)\n",
        "\n",
        "    normalize = transforms.Normalize(mean=mean, std=std)\n",
        "\n",
        "    # Apply normalization to each image\n",
        "    normalized_images = torch.zeros_like(images)\n",
        "    for i in range(images.shape[0]):\n",
        "        normalized_images[i] = normalize(images[i])\n",
        "\n",
        "    return normalized_images\n",
        "\n",
        "#############################################################################\n",
        "# 8. Main Training Function\n",
        "#############################################################################\n",
        "def train_model(num_epochs=300, batch_size=128, width_multiplier=0.6, dropout=0.3, se_reduction=16,\n",
        "                use_mixup=True, mixup_alpha=1.0):\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    print(\"Using device:\", device)\n",
        "\n",
        "    # Hyperparameters\n",
        "    initial_lr = 0.1\n",
        "    weight_decay = 5e-4\n",
        "    bn_momentum = 0.9\n",
        "\n",
        "    # 1) Load Data\n",
        "    train_loader, test_loader = get_cifar10_dataloaders(batch_size=batch_size)\n",
        "\n",
        "    # 2) Create Model with SE blocks\n",
        "    model = NarrowResNet18(\n",
        "        num_classes=10,\n",
        "        width_multiplier=width_multiplier,\n",
        "        bn_momentum=bn_momentum,\n",
        "        dropout=dropout,\n",
        "        se_reduction=se_reduction\n",
        "    ).to(device)\n",
        "\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    print(f\"Total parameters: {total_params:,}\")\n",
        "    assert total_params < 5_000_000, \"Model exceeds 5 million parameters!\"\n",
        "\n",
        "    # 3) Define Loss (with label smoothing) and Optimizer\n",
        "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)  # Increased label smoothing from 0.05 to 0.1\n",
        "    optimizer = optim.SGD(\n",
        "        model.parameters(), lr=initial_lr, momentum=0.9, weight_decay=weight_decay, nesterov=True\n",
        "    )\n",
        "\n",
        "    # 4) Learning Rate Schedule with Warmup + Cosine\n",
        "    warmup_epochs = 25\n",
        "    scheduler_cosine = optim.lr_scheduler.CosineAnnealingLR(\n",
        "        optimizer,\n",
        "        T_max=(num_epochs - warmup_epochs),\n",
        "        eta_min=1e-5  # Reduced eta_min to allow learning rate to go lower\n",
        "    )\n",
        "\n",
        "    # 5) Training Loop\n",
        "    best_acc = 0.0\n",
        "    best_model_state = None\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # -------------- Warmup stage --------------\n",
        "        if epoch < warmup_epochs:\n",
        "            # Linearly interpolate from 0.01 to initial_lr over warmup_epochs\n",
        "            warmup_start_lr = 0.01\n",
        "            progress = (epoch + 1) / warmup_epochs  # goes from 1/warmup_epochs â†’ 1.0\n",
        "            new_lr = warmup_start_lr + (initial_lr - warmup_start_lr) * progress\n",
        "\n",
        "            for param_group in optimizer.param_groups:\n",
        "                param_group['lr'] = new_lr\n",
        "\n",
        "        # -------------- Cosine stage --------------\n",
        "        else:\n",
        "            # Step the cosine scheduler\n",
        "            scheduler_cosine.step()\n",
        "\n",
        "        # ----- Training as usual -----\n",
        "        train_loss, train_acc = train_one_epoch(\n",
        "            model, device, train_loader, criterion, optimizer,\n",
        "            use_mixup=use_mixup, mixup_alpha=mixup_alpha\n",
        "        )\n",
        "\n",
        "        test_loss, test_acc = evaluate(model, device, test_loader, criterion)\n",
        "\n",
        "        # Track best accuracy\n",
        "        if test_acc > best_acc:\n",
        "            best_acc = test_acc\n",
        "            best_model_state = model.state_dict().copy()  # Save a copy of the model state\n",
        "\n",
        "        if (epoch + 1) % 10 == 0 or epoch == num_epochs - 1:\n",
        "            print(f\"Epoch [{epoch+1}/{num_epochs}] \"\n",
        "                  f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% | \"\n",
        "                  f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%\")\n",
        "\n",
        "    print(f\"\\nBest Test Accuracy: {best_acc:.2f}%\")\n",
        "\n",
        "    # Load best model weights\n",
        "    model.load_state_dict(best_model_state)\n",
        "\n",
        "    return model, best_acc\n",
        "\n",
        "#############################################################################\n",
        "# 9. Inference and Submission Generation\n",
        "#############################################################################\n",
        "def generate_submission(model, device='cuda', use_tta=True, num_augmentations=10):\n",
        "    \"\"\"\n",
        "    Run inference on the test set and generate a submission file.\n",
        "    \"\"\"\n",
        "    # 1) Find and load test data\n",
        "    test_file_path = locate_test_file()\n",
        "    if test_file_path is None:\n",
        "        print(\"Failed to locate test file. Submission generation aborted.\")\n",
        "        return\n",
        "\n",
        "    # 2) Load and preprocess test data\n",
        "    test_images = load_custom_test_set(test_file_path)\n",
        "    test_images = preprocess_test_images(test_images)\n",
        "\n",
        "    # 3) Create DataLoader\n",
        "    test_dataset = torch.utils.data.TensorDataset(test_images)\n",
        "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=False)\n",
        "\n",
        "    # 4) Run inference with or without TTA\n",
        "    model.eval()\n",
        "    all_predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            inputs = batch[0].to(device)\n",
        "\n",
        "            if use_tta:\n",
        "                # Apply test-time augmentation\n",
        "                outputs = test_time_augmentation(model, inputs, num_augmentations=num_augmentations)\n",
        "                _, predicted = outputs.max(1)\n",
        "            else:\n",
        "                # Standard inference\n",
        "                outputs = model(inputs)\n",
        "                _, predicted = outputs.max(1)\n",
        "\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "    # 5) Create submission file\n",
        "    submission = pd.DataFrame({\n",
        "        'ID': np.arange(len(all_predictions)),\n",
        "        'Labels': all_predictions\n",
        "    })\n",
        "\n",
        "    # Save submission\n",
        "    submission_file = 'improved_submission.csv'\n",
        "    submission.to_csv(submission_file, index=False)\n",
        "    print(f\"Submission file saved as {submission_file}\")\n",
        "\n",
        "    return submission\n",
        "\n",
        "#############################################################################\n",
        "# 10. Full Training and Submission Pipeline\n",
        "#############################################################################\n",
        "def run_full_pipeline():\n",
        "    # 1) Train the model\n",
        "    model, best_acc = train_model(\n",
        "        num_epochs=300,         # Increased from 250 to 300\n",
        "        batch_size=128,\n",
        "        width_multiplier=0.6,   # Increased from 0.5 to 0.6\n",
        "        dropout=0.3,            # Decreased from 0.5 to 0.3\n",
        "        se_reduction=16,        # SE block reduction ratio\n",
        "        use_mixup=True,         # Enable mixup augmentation\n",
        "        mixup_alpha=1.0         # Mixup alpha parameter\n",
        "    )\n",
        "\n",
        "    # 2) Save the trained model\n",
        "    torch.save(model.state_dict(), \"improved_resnet18_state.pth\")\n",
        "    print(\"Model saved to improved_resnet18_state.pth\")\n",
        "\n",
        "    # 3) Generate submission with test-time augmentation\n",
        "    submission = generate_submission(model, use_tta=True, num_augmentations=10)\n",
        "\n",
        "    return model, submission\n",
        "\n",
        "# Execute if running as script\n",
        "if __name__ == \"__main__\":\n",
        "    run_full_pipeline()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jHSXl-cP9rdp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}